{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7016bf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "import os\n",
    "os.environ['HADOOP_CONF_DIR'] = '/etc/hadoop/conf'\n",
    "os.environ['YARN_CONF_DIR'] = '/etc/hadoop/conf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffcf9524",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, timedelta, datetime\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.window import Window \n",
    "from pyspark.sql import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16f68ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Class path contains multiple SLF4J bindings.\n",
      "SLF4J: Found binding in [jar:file:/usr/lib/spark/jars/slf4j-log4j12-1.7.30.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/usr/lib/hadoop/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
      "SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\n",
      "2023-01-26 18:30:30,086 WARN util.Utils: Your hostname, fhmst38qln6c3o1fij70 resolves to a loopback address: 127.0.1.1; using 172.16.0.19 instead (on interface eth0)\n",
      "2023-01-26 18:30:30,087 WARN util.Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "2023-01-26 18:30:32,338 WARN util.Utils: spark.executor.instances less than spark.dynamicAllocation.minExecutors is invalid, ignoring its setting, please update your configs.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    ".builder \\\n",
    ".master(\"yarn\")\\\n",
    ".config(\"spark.driver.memory\", \"2g\") \\\n",
    ".config(\"spark.executor.memory\", \"2g\") \\\n",
    ".appName(\"Project8\") \\\n",
    ".getOrCreate()                               "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b60e7f6",
   "metadata": {},
   "source": [
    "# Функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "444d1f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выбирает все даты, попадающие в заданный диапазон.\n",
    "# Даты передаются в формате \"2022-01-01\"\n",
    "def select_dates(start_date: str, end_date: str) -> list:\n",
    "    try:\n",
    "        start_date = datetime.fromisoformat(start_date)\n",
    "        end_date = datetime.fromisoformat(end_date)\n",
    "    except:\n",
    "        print('Неверный формат даты!') # ПИСАТЬ В ЛОГ!!!!!\n",
    "    # Список дат в формате ['/user/master/data/events/date=2020-10-02', ...]\n",
    "    paths_list = []\n",
    "    # Количество дней между датами\n",
    "    delta = end_date - start_date\n",
    "    \n",
    "    if delta.days < 0:\n",
    "        print ('Указан слишком маленький диапазон!')  # ПИСАТЬ В ЛОГ!!!!!\n",
    "    for i in range(delta.days + 1):\n",
    "        paths_list.append('/user/master/data/geo/events/date=' + (start_date + timedelta(i)).__str__()[:10])\n",
    "    return paths_list\n",
    "\n",
    "calculate_dist = F.lit(2*6371) * F.asin(\n",
    "        F.sqrt(\n",
    "            F.pow(F.sin((F.radians(F.col(\"lat\")) - F.radians(F.col(\"ltt\"))) / 2), 2) +\n",
    "            F.cos(F.radians(F.col(\"lat\"))) * F.radians(F.cos(F.col(\"ltt\"))) *\n",
    "            F.pow(F.sin((F.radians(F.col(\"lon\")) - F.radians(F.col(\"lng\"))) / 2), 2)\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98547130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/user/master/data/geo/events/date=2022-01-01',\n",
       " '/user/master/data/geo/events/date=2022-01-02',\n",
       " '/user/master/data/geo/events/date=2022-01-03']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_dates('2022-01-01', '2022-01-03')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc09d28",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fdc114",
   "metadata": {},
   "source": [
    "### Действия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dff9a4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#  Добавить проверку на количество записей в лог\n",
    "try:\n",
    "    activities = spark.read.parquet(*select_dates('2022-01-01', '2022-01-02'))\n",
    "except:\n",
    "    print('Нет данных за указанный диапазон!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d624ef31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------+------------+------------------+------------------+\n",
      "|event                                                                     |event_type  |lat               |lon               |\n",
      "+--------------------------------------------------------------------------+------------+------------------+------------------+\n",
      "|[,, 2022-01-01 19:39:54,,,,,,,,,,,, 376484,, 141560]                      |subscription|-34.79058202339126|149.62371004159567|\n",
      "|[,,,, same OS,, 9040,, 593944, 62475, 2021-01-01 13:51:56.362816053,,,,,,]|message     |-32.27676278030154|152.01807950723008|\n",
      "|[,, 2022-01-01 01:45:29,,,,,,,,,,,, 387849,, 251849]                      |subscription|-42.22344734393438|147.75004888501377|\n",
      "+--------------------------------------------------------------------------+------------+------------------+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "activities.show(3, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3c9385c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(event,StructType(List(StructField(admins,ArrayType(LongType,true),true),StructField(channel_id,LongType,true),StructField(datetime,StringType,true),StructField(media,StructType(List(StructField(media_type,StringType,true),StructField(src,StringType,true))),true),StructField(message,StringType,true),StructField(message_channel_to,LongType,true),StructField(message_from,LongType,true),StructField(message_group,LongType,true),StructField(message_id,LongType,true),StructField(message_to,LongType,true),StructField(message_ts,StringType,true),StructField(reaction_from,StringType,true),StructField(reaction_type,StringType,true),StructField(subscription_channel,LongType,true),StructField(subscription_user,StringType,true),StructField(tags,ArrayType(StringType,true),true),StructField(user,StringType,true))),true),StructField(event_type,StringType,true),StructField(lat,DoubleType,true),StructField(lon,DoubleType,true)))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activities.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e5aa16",
   "metadata": {},
   "source": [
    "### Города"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15f245d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = spark.read.csv('/user/flaviusoct/data/coord', sep=';', header=True).withColumnRenamed('lat', 'ltt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "003f0c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------+--------+\n",
      "| id|     city|     ltt|     lng|\n",
      "+---+---------+--------+--------+\n",
      "|  1|   Sydney| -33,865|151,2094|\n",
      "|  2|Melbourne|-37,8136|144,9631|\n",
      "|  3| Brisbane|-27,4678|153,0281|\n",
      "+---+---------+--------+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "cities.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478f75fe",
   "metadata": {},
   "source": [
    "## Обработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff452ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удаляем строки с пропущенными значениями координат\n",
    "\n",
    "activities_new = activities.where(\"lat IS NOT NULL AND lon IS NOT NULL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1032735c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Делаем одну колонку со временем\n",
    "# и добавляем колонку с уникальным id\n",
    "activities_new = activities_new \\\n",
    ".withColumn('datetime', F.coalesce(F.col('event.datetime'), F.col('event.message_ts')).cast('timestamp')) \\\n",
    ".orderBy(F.asc('datetime')) \\\n",
    ".withColumn('activity_id', F.monotonically_increasing_id())\n",
    "# В этом точно есть, ибо группировать ниже надо по какому-то общему идентификатору\n",
    "# в сообщениях и иных действиях. По умолчанию его нет.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acecbc50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:>                                                         (0 + 4) / 19]\r"
     ]
    }
   ],
   "source": [
    "activities_new.show(3, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af49aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_new = cities \\\n",
    ".withColumn(\"ltt\", F.regexp_replace(F.col(\"ltt\"), pattern=',', replacement='.').cast(\"double\")) \\\n",
    ".withColumn(\"lng\", F.regexp_replace(F.col(\"lng\"), pattern=',', replacement='.').cast(\"double\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e630752f",
   "metadata": {},
   "source": [
    "## Операции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48e076e",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities_new = activities_new.crossJoin(cities_new) \\\n",
    "        .withColumn('distance', calculate_dist) \\\n",
    "        .withColumn(\"distance_rank\",\n",
    "                    F.row_number().over(Window.partitionBy(\"activity_id\").orderBy(\"distance\"))) \\\n",
    "        .where(\"distance_rank == 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0acb0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities_new.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa28a28",
   "metadata": {},
   "source": [
    "## Создаём витрину"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4584b829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_user_view(df: DataFrame) -> DataFrame:\n",
    "    messages = df.where(\"event_type='message' AND event.message_ts IS NOT NULL\") \\\n",
    "    .select(F.col('event.message_from').alias('user_id'),\n",
    "            F.to_date(F.col('event.message_ts')).alias('msg_date'),\n",
    "            F.col('city')\n",
    "           ).distinct()\n",
    "    \n",
    "    '''\n",
    "    act_city = messages \\\n",
    "    .withColumn(\n",
    "        'user_messages_rank', F.row_number().over(Window().partitionBy(['user_id']).orderBy(F.desc('msg_date')))\n",
    "    ).where('user_messages_rank == 1') \\\n",
    "    .select(F.col('user_id'), F.col('city').alias('act_city'))\n",
    "    \n",
    "    home_city = messages. \\\n",
    "    withColumn(\"date_group_rank\",\n",
    "               F.row_number().over(Window.partitionBy(\"user_id\", \"city\").orderBy(\"msg_date\"))) \\\n",
    "    .selectExpr('*', 'date_sub(msg_date, date_group_rank) as date_group') \\\n",
    "    .groupBy(\"user_id\", \"city\", \"date_group\") \\\n",
    "    .agg(F.count(\"*\").alias(\"cnt_days\")) \\\n",
    "    .select(\"user_id\", \"city\", \"cnt_days\") \\\n",
    "    .where(\"cnt_days > 1\") \\\n",
    "    .withColumn('max_cnt', F.max('cnt_days').over(Window.partitionBy(\"user_id\", \"city\"))) \\\n",
    "    .where(F.col('cnt_days') == F.col('max_cnt')) \\\n",
    "    .drop('max_cnt', 'cnt_days') \\\n",
    "    .withColumn(\"home_city\", F.first(\"city\").over(Window.partitionBy(\"user_id\"))) \\\n",
    "    .drop(\"city\") \\\n",
    "    #.withColumnRenamed(\"city\", \"home_city\")\n",
    "\n",
    "    '''\n",
    "    travel_count = messages \\\n",
    "    .groupBy(\"user_id\") \\\n",
    "    .agg(F.count(\"*\").alias(\"travel_count\"))\n",
    "    \n",
    "    travel_array = messages \\\n",
    "    .orderBy(\"msg_date\") \\\n",
    "    .groupBy(\"user_id\") \\\n",
    "    .agg(F.collect_list(\"city\").alias(\"travel_array\")) \\\n",
    "    .drop(\"city\", \"msg_date\")\n",
    "    \n",
    "    print(1)\n",
    "    local_time = messages \\\n",
    "    .withColumn('message_rank_by_user',\n",
    "                F.row_number().over(Window.partitionBy(\"user_id\").orderBy(F.desc('msg_date')))\n",
    "               ).where('message_rank_by_user == 1') \\\n",
    "    .select(F.col('user_id'), F.col('msg_date').alias('')).orderBy(F.col('user_id'))\n",
    "    \n",
    "    print(2)\n",
    "    user_registration = messages \\\n",
    "        .withColumn('message_order_rank', F.min('msg_date').over(Window.partitionBy(\"user_id\"))) \\\n",
    "        .where(F.col('msg_date') == F.col('message_order_rank')) \\\n",
    "        .select(F.col(\"user_id\"), F.col('msg_date')) \\\n",
    "        .groupBy(\"user_id\") \\\n",
    "        .agg(F.first(\"msg_date\")).orderBy(F.col('user_id'))\n",
    "    \n",
    "    local_time.show(7)\n",
    "    user_registration.show(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "73358793",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 29:====>            (5 + 4) / 19][Stage 36:>                 (0 + 0) / 1]\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mactivities_new\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtruncate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/spark/python/pyspark/sql/dataframe.py:442\u001b[0m, in \u001b[0;36mDataFrame.show\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jdf\u001b[38;5;241m.\u001b[39mshowString(n, \u001b[38;5;241m20\u001b[39m, vertical))\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 442\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshowString\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtruncate\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:1303\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1296\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1298\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1299\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1300\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1301\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1303\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1304\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1305\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1307\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:1033\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1031\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m   1032\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1033\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1034\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[1;32m   1035\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:1200\u001b[0m, in \u001b[0;36mGatewayConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JNetworkError(\n\u001b[1;32m   1197\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError while sending\u001b[39m\u001b[38;5;124m\"\u001b[39m, e, proto\u001b[38;5;241m.\u001b[39mERROR_ON_SEND)\n\u001b[1;32m   1199\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1200\u001b[0m     answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m   1201\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[1;32m   1202\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m answer\u001b[38;5;241m.\u001b[39mstartswith(proto\u001b[38;5;241m.\u001b[39mRETURN_MESSAGE):\n",
      "File \u001b[0;32m/usr/lib/python3.8/socket.py:669\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 669\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    670\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    671\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "activities_new.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a0246294",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark._jsc.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1c344e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -ls /user/master/data/geo/events/date=2022-01-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d7a667",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
